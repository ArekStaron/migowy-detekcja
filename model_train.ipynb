{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3589b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ab69d",
   "metadata": {},
   "source": [
    "robienie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6415f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# merging data\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "dataset_dir = \"Sign-Language-Digits-Dataset-master\\Dataset\"\n",
    "dataset_dir_2 = \"data_2\"\n",
    "\n",
    "dataset_dirs = [dataset_dir , dataset_dir_2]\n",
    "\n",
    "out_dir = Path(\"merged_dataset\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for d in dataset_dirs:\n",
    "    for cls in os.listdir(d):\n",
    "        src = Path(d) / cls\n",
    "        if not src.is_dir(): continue\n",
    "        dst = out_dir / cls\n",
    "        dst.mkdir(exist_ok=True)\n",
    "        for f in os.listdir(src):\n",
    "            shutil.copy(src / f, dst / f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76a4dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 21\n",
      "2000 52\n",
      "3000 95\n",
      "4000 98\n",
      "5000 102\n",
      "6000 111\n",
      "7000 111\n",
      "8000 111\n",
      "9000 137\n",
      "10000 145\n",
      "11000 152\n",
      "12000 166\n",
      "13000 166\n",
      "14000 166\n",
      "15000 166\n",
      "16000 166\n",
      "17000 166\n",
      "18000 166\n",
      "19000 166\n",
      "20000 166\n",
      "21000 166\n",
      "22000 166\n",
      "23000 166\n",
      "24000 166\n",
      "25000 166\n",
      "26000 166\n",
      "27000 166\n",
      "28000 166\n",
      "29000 166\n",
      "30000 168\n",
      "31000 187\n",
      "32000 432\n",
      "33000 524\n",
      "34000 534\n",
      "35000 552\n",
      "36000 577\n",
      "37000 577\n",
      "38000 578\n",
      "39000 578\n",
      "40000 578\n",
      "41000 578\n",
      "42000 578\n",
      "43000 578\n",
      "44000 578\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mp_hands =  mp.solutions.hands\n",
    "hands_model  = mp_hands.Hands(static_image_mode=True, max_num_hands=1 , min_detection_confidence=0.1)\n",
    "\n",
    "\n",
    "data = []\n",
    "errors = []\n",
    "\n",
    "count = 0\n",
    "merged_data_dir = \"merged_dataset\"\n",
    "for class_name in os.listdir(merged_data_dir):\n",
    "    class_dir = os.path.join(merged_data_dir , class_name)\n",
    "\n",
    "\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        count +=1\n",
    "        image_path = os.path.join(class_dir , image_file)\n",
    "        image  =cv2.imread(image_path)\n",
    "        image =  cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image , (128 , 128))\n",
    "        results = hands_model.process(image)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            points = torch.tensor([[p.x , p.y , p.z] for p in hand_landmarks.landmark])\n",
    "            data.append((points ,class_name))\n",
    "        else:\n",
    "            errors.append(image_path)\n",
    "        \n",
    "        if count%1000 == 0:\n",
    "            print(count , len(errors))\n",
    "\n",
    "   \n",
    "torch.save(data , \"tensordata\" )        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386372ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape obrazu: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"merged_dataset/S/0.JPG\"\n",
    "image = cv2.imread(image_path)\n",
    "print(\"Shape obrazu:\", image.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4a9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#moj komputer nie daje rady z przetwarzaniem większej ilości niż \n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "merged_data_dir = \"merged_dataset\"\n",
    "\n",
    "\n",
    "def process_image(class_name, img_file):\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands_model = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.1)    \n",
    "    \n",
    "    img_path = os.path.join(merged_data_dir, class_name, img_file)\n",
    "    \n",
    "    image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    results = hands_model.process(image)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        pts = torch.tensor([[p.x, p.y, p.z] for p in results.multi_hand_landmarks[0].landmark])\n",
    "        \n",
    "        return (pts, int(class_name))\n",
    "    return None\n",
    "\n",
    "\n",
    "tasks = [(class_name, img_file) \n",
    "         \n",
    "         for class_name in os.listdir(merged_data_dir)\n",
    "         \n",
    "         for img_file in os.listdir(os.path.join(merged_data_dir, class_name))]\n",
    "\n",
    "data = []\n",
    "\n",
    "count = 0\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    \n",
    "    for res in executor.map(lambda t: process_image(*t), tasks):\n",
    "        count +=1\n",
    "        if res is not None:\n",
    "            \n",
    "            data.append(res)\n",
    "        if count % 1000 ==0:\n",
    "            print(f\"{count} ilość obrazów {len(data)} \")\n",
    "\n",
    "torch.save(data, \"hands_tensor_data_multithread.pt\")\n",
    "print(f\"Gotowe! Liczba próbek: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wszystkich plików: 44062\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total = sum(len(files) for _, _, files in os.walk(merged_data_dir))\n",
    "print(\"Liczba wszystkich plików:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a793f1",
   "metadata": {},
   "source": [
    "szacowanie ile zajmie przejście przez dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: torch.Size([21, 3])\n",
      "Czas przetwarzania: 0.06308627128601074 sekund\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "mp_hands = mp.solutions.hands\n",
    "hands_model = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.1)\n",
    "\n",
    "image_path = r\"merged_dataset\\0\\IMG_1128.JPG\"  \n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "start = time.time()\n",
    "\n",
    "results = hands_model.process(image)\n",
    "\n",
    "if results.multi_hand_landmarks:\n",
    "    hand_landmarks = results.multi_hand_landmarks[0]\n",
    "    points = torch.tensor([[p.x, p.y, p.z] for p in hand_landmarks.landmark])\n",
    "    print(\"Tensor shape:\", points.shape)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Czas przetwarzania:\", end - start, \"sekund\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2636fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7099e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_data =  torch.load(\"tensordata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a489110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(\"merged_dataset\")\n",
    "label_map = {k : v  for v , k in enumerate(labels)}\n",
    "\n",
    "X = torch.stack([t[0] for t in tensor_data])\n",
    "Y = torch.stack([torch.tensor(label_map[t[1]]) for t in tensor_data])\n",
    "X.shape\n",
    "\n",
    "X = X.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec84013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([43484, 1, 21, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6b5467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset ,DataLoader ,random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(X , Y)\n",
    "\n",
    "train_len = int(0.8 * len(dataset))\n",
    "valid_len= len(dataset) - train_len\n",
    "\n",
    "train_dataset , valid_dataset = random_split(dataset , [train_len , valid_len])\n",
    "\n",
    "traning_loader = DataLoader( train_dataset , batch_size= 32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset , batch_size=32 , shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5c0df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " 'A': 10,\n",
       " 'B': 11,\n",
       " 'C': 12,\n",
       " 'D': 13,\n",
       " 'E': 14,\n",
       " 'F': 15,\n",
       " 'G': 16,\n",
       " 'H': 17,\n",
       " 'I': 18,\n",
       " 'J': 19,\n",
       " 'K': 20,\n",
       " 'L': 21,\n",
       " 'M': 22,\n",
       " 'N': 23,\n",
       " 'O': 24,\n",
       " 'P': 25,\n",
       " 'Q': 26,\n",
       " 'R': 27,\n",
       " 'S': 28,\n",
       " 'T': 29,\n",
       " 'U': 30,\n",
       " 'V': 31,\n",
       " 'W': 32,\n",
       " 'X': 33,\n",
       " 'Y': 34,\n",
       " 'Z': 35}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43475f15",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.5)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/arosk/OneDrive/Pulpit/Programy/migowy detekcja/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Sing_language_model(nn.Module):\n",
    "    def __init__(self , input_size , hidden_size ):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    def detect():\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
